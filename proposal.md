---
layout: page
title: Project Proposal
permalink: /proposal/
---

### Project Title: Image Captioning

### Project Idea

We want to train the machine to detect details from an image (such as ) and then output a sentence to describe the image.

For example, for the following image, the model should detect a brown dog and a blue toy. And it can output a sentence like "A dog is trying to catch a blue and toy."

![](../assets/example.jpg)

### Dataset Details

We will use [Flickr8K](http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html), [Flickr30K](http://shannon.cs.illinois.edu/DenotationGraph/), and [COCO](http://cocodataset.org/).

### Software

[Amazon Web Services](https://aws.amazon.com/)

[FloydHub](https://www.floydhub.com)

### Libraries

[TensorFlow](https://www.tensorflow.org/)

### Papers

Karpathy, A., & Fei-Fei, L. (2015). Deep visual-semantic alignments for generating image descriptions. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). doi:10.1109/cvpr.2015.7298932

### Teammate

[Yizhen Chen](https://sharedcare.io/)

[Tiancheng Luo](https://iLtc.io)

### Progress Milestones

