---
layout: post
title: Progress Report
permalink: /report/
---

# Project Proposal

Click [here](../proposal/) to view our project proposal.

# What We Did

Our original goal was first to build and train a model that could detect details, or what we call tags, from the images, and then create another model that could take the tags and return captions of the pictures. 

We read some papers related to Image Captioning and Long Short-Term Memory. We also analyzed some models designed by others, such as `TensorFlow Slim Image Classification Model` and `Show and Tell: A Neural Image Caption Generator`. However, we find there are some problems with the models that could convert images to tags. 

One problem was the unrelated tags. When we tried to use a pre-trained model called `Inception V4` to convert the images, the model returned some tags that were not related to the captions. For example, for the following picture, the model returned `Labrador retriever`, `golden retriever`, `Chesapeake Bay retriever`, `Rhodesian ridgeback`, `American Staffordshire terrier`, `Staffordshire terrier`, `American pit bull terrier` etc. It seems that the model was more interested in detecting the dog breeds instead of what the dog was doing.

![](../assets/example.jpg)

Another problem was the training time and resources. When we followed an instruction from TensorFlow Slim Image Classification Model, we had to download a 13 GB original datasets and spent another 70 GB to store the formatted datasets. When the training begins, it was so slow that we supposed to wait for a week before got the result. Since we were training the model on a paid GPU machine, we could not offer such long training time.

As a result, we decided to use the pre-trained model and begin to build the second model. 

Before we decided to give up building the first model, we had generated images to tags for `Flickr8K`. You can click [here]() to download the dataset that we generated. 

# What We Will Do

